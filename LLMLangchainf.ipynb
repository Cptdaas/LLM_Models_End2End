{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "senetence =\"If Vinod Tiwari is a student at IIT Delhi pursuing an MS in AI after this date, or if this information is not widely accessible, you may want to refer to the official IIT Delhi website, academic records, or contact the institution directly for the most accurate and up-to-date information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If Vinod Tiwari is a student at IIT Delhi pursuing an MS in AI after this date, or if this information is not widely accessible, you may want to refer to the official IIT Delhi website, academic records, or contact the institution directly for the most accurate and up-to-date information.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senetence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "prompt =f'''\n",
    "Please extract the following information from the given text and retrun it as a JSON object:\n",
    "\n",
    "name \n",
    "college\n",
    "grades \n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{senetence}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease extract the following information from the given text and retrun it as a JSON object:\\n\\nname \\ncollege\\ngrades \\nclub\\n\\nThis is the body of text to extract the information from:\\nIf Vinod Tiwari is a student at IIT Delhi pursuing an MS in AI after this date, or if this information is not widely accessible, you may want to refer to the official IIT Delhi website, academic records, or contact the institution directly for the most accurate and up-to-date information.\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from openai import OpenAI\n",
    "# client =OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt_Template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name =PromptTemplate(\n",
    "    input_variables=[\"Country\"],\n",
    "    template=\"Can you tell me the Capital of {country} ?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 =prompt_template_name.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 =prompt_template_name.format(country=\"Russia\")\n",
    "prompt3 =prompt_template_name.format(country=\"China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Can you tell me the Capital of India ?',\n",
       " 'Can you tell me the Capital of Russia ?',\n",
       " 'Can you tell me the Capital of China ?')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1, prompt2, prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me the Capital of India ?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =PromptTemplate.from_template(\"What is a good name for a company that makes a {product}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 =prompt.format(product=\"Guns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes a Guns?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent:\n",
    "* For extracting real time info i am going to use serp api /n by using serp api i will be able to use real time info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing API key file \n",
    "import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "serp_api =API.ser_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, load_tools,initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "key =\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "client =OpenAI(openai_api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero shot prompting \n",
    "prompt =\"Can you tell me total no of country in asia? give top 10 countries name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(client.predict(prompt).strip())\n",
    "# RateLimitError  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\"], serpapi_api_key=serp_api, llm=client)\n",
    "agent_type = AgentType.ZERO_SHOT_REACT_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent =initialize_agent(tools,client,agent=agent_type,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.run(\"Can tell me about  world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool =load_tools(['wikipedia'],llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent =initialize_agent(tool,client,agent=agent_type,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.run(\"Can tell me about  world cup?\")\n",
    "# RateLimitError                            Traceback (most recent call last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain:\n",
    "* Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.\n",
    "\n",
    "* LCEL is great for constructing your own chains, but itâ€™s also nice to have chains that you can use off-the-shelf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x000001D7B97A68F0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001D7B97B51B0>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt =PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain =LLMChain(llm=client, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.run(\"Wine\")\n",
    "# RateLimitError     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template =PromptTemplate(\n",
    "    input_variables=[\"startup_name\"],\n",
    "    template =\"I want to start a startup for {startup-name} , suggest me a good name for this\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain =LLMChain(llm=client, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items =PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"Suggest some strategies for {name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_chain =LLMChain(llm=client, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining two chain with simple sequntil chain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "chains =SimpleSequentialChain(chains=[name_chain,strategies_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.run(\"artificial Inntelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets try too understand the sequnetial chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name =PromptTemplate(\n",
    "    input_variables=[\"cuisine\"],\n",
    "    template =\"I want open a resturent for {cuisine}, suggest a fancy name for it\"\n",
    ")\n",
    "name_chain =LLMChain(llm=client, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name =PromptTemplate(\n",
    "    input_variables=[\"restaurant_name\"],\n",
    "    template =\"Suggest some menu items for {restaurant_name}\"\n",
    ")\n",
    "food_item_chain =LLMChain(llm=client, prompt=prompt_template_name, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(\n",
    "    chains=[name_chain, food_item_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\", \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain({\"cuisine\":\"Indian\"})\n",
    "# RateLimitError                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Buffer Memory\n",
    "we can attach memory to remember all previous conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory =ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template1 =PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What would be a good name for campany that produces {product}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=ConversationBufferMemory(), prompt=PromptTemplate(input_variables=['product'], template='What would be a good name for campany that produces {product}.'), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x000001D7B97A68F0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001D7B97B51B0>, openai_api_key='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', openai_proxy=''))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLMChain(llm=client,prompt=prompt_template1,memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Chain:\n",
    "* Converation buffer memory goes frowing endlessly\n",
    "* Hust remember last 5 conversation and if Just remember  last 10-20 Convesation chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo  =ConversationChain(llm=OpenAI(openai_api_key=key, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'input'], template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convo.run(\"Who won the first cricket worldcup?\")\n",
    "# convo.run(\"tell 5+5\")\n",
    "# convo.run(\"what is cappital of jermany?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo  =ConversationChain(llm=OpenAI(openai_api_key=key, temperature=0.7),memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convo.run(\"Whoo won the first world cup>\")\n",
    "# convo.run(\"tell 5+5\")\n",
    "# convo.run(\"what is cappital of jermany?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Pipeline using Langchain wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import Pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
